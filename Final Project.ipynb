{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "9734840d",
   "metadata": {},
   "source": [
    "# Capstone Project: Stock Returns Predictor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "90f4a190",
   "metadata": {},
   "outputs": [],
   "source": [
    "#!pip install -U pip\n",
    "#!pip install -U setuptools wheel\n",
    "#!pip install -U \"mxnet<2.0.0\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "6fb68d40",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Archive:  the-winton-stock-market-challenge.zip\n",
      "  inflating: sample_submission_2.csv.zip  \n",
      "  inflating: test_2.csv.zip          \n",
      "  inflating: train.csv.zip           \n"
     ]
    }
   ],
   "source": [
    "!unzip -o the-winton-stock-market-challenge.zip"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "1c53877c",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Archive:  train.csv.zip\n",
      "  inflating: train.csv               \n",
      "   creating: __MACOSX/\n",
      "  inflating: __MACOSX/._train.csv    \n",
      "Archive:  test_2.csv.zip\n",
      "  inflating: test_2.csv              \n",
      "  inflating: __MACOSX/._test_2.csv   \n",
      "Archive:  sample_submission_2.csv.zip\n",
      "  inflating: sample_submission_2.csv  \n",
      "  inflating: __MACOSX/._sample_submission_2.csv  \n"
     ]
    }
   ],
   "source": [
    "#!unzip -o train.csv.zip\n",
    "#!unzip test_2.csv.zip\n",
    "#!unzip sample_submission_2.csv.zip"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "5a3931c3",
   "metadata": {},
   "outputs": [],
   "source": [
    "#!pip install autogluon --no-cache-dir"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "400417e4",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Matplotlib is building the font cache; this may take a moment.\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "from autogluon.tabular import TabularPredictor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "69609a7f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index(['Id', 'Feature_1', 'Feature_2', 'Feature_3', 'Feature_4', 'Feature_5',\n",
       "       'Feature_6', 'Feature_7', 'Feature_8', 'Feature_9',\n",
       "       ...\n",
       "       'Ret_175', 'Ret_176', 'Ret_177', 'Ret_178', 'Ret_179', 'Ret_180',\n",
       "       'Ret_PlusOne', 'Ret_PlusTwo', 'Weight_Intraday', 'Weight_Daily'],\n",
       "      dtype='object', length=211)"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "training = pd.read_csv(\"train.csv\")\n",
    "training.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "af4d04fa",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Id</th>\n",
       "      <th>Feature_1</th>\n",
       "      <th>Feature_2</th>\n",
       "      <th>Feature_3</th>\n",
       "      <th>Feature_4</th>\n",
       "      <th>Feature_5</th>\n",
       "      <th>Feature_6</th>\n",
       "      <th>Feature_7</th>\n",
       "      <th>Feature_8</th>\n",
       "      <th>Feature_9</th>\n",
       "      <th>...</th>\n",
       "      <th>Ret_175</th>\n",
       "      <th>Ret_176</th>\n",
       "      <th>Ret_177</th>\n",
       "      <th>Ret_178</th>\n",
       "      <th>Ret_179</th>\n",
       "      <th>Ret_180</th>\n",
       "      <th>Ret_PlusOne</th>\n",
       "      <th>Ret_PlusTwo</th>\n",
       "      <th>Weight_Intraday</th>\n",
       "      <th>Weight_Daily</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>8.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>75751</td>\n",
       "      <td>0.2254</td>\n",
       "      <td>11.0</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.002688</td>\n",
       "      <td>0.002246</td>\n",
       "      <td>-0.000838</td>\n",
       "      <td>-6.953224e-04</td>\n",
       "      <td>0.000003</td>\n",
       "      <td>-0.001974</td>\n",
       "      <td>-0.019512</td>\n",
       "      <td>0.028846</td>\n",
       "      <td>1.251508e+06</td>\n",
       "      <td>1.564385e+06</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>3.0</td>\n",
       "      <td>0.388896</td>\n",
       "      <td>17369</td>\n",
       "      <td>0.0166</td>\n",
       "      <td>13.0</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.000129</td>\n",
       "      <td>0.000123</td>\n",
       "      <td>0.000248</td>\n",
       "      <td>3.315418e-07</td>\n",
       "      <td>0.000003</td>\n",
       "      <td>0.000027</td>\n",
       "      <td>-0.002939</td>\n",
       "      <td>-0.010253</td>\n",
       "      <td>1.733950e+06</td>\n",
       "      <td>2.167438e+06</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>3</td>\n",
       "      <td>NaN</td>\n",
       "      <td>-0.696727</td>\n",
       "      <td>0.739591</td>\n",
       "      <td>-0.167928</td>\n",
       "      <td>9.0</td>\n",
       "      <td>0.471947</td>\n",
       "      <td>8277</td>\n",
       "      <td>0.3650</td>\n",
       "      <td>9.0</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.000524</td>\n",
       "      <td>-0.000394</td>\n",
       "      <td>0.000116</td>\n",
       "      <td>5.322557e-04</td>\n",
       "      <td>0.000274</td>\n",
       "      <td>0.000784</td>\n",
       "      <td>-0.024791</td>\n",
       "      <td>0.015711</td>\n",
       "      <td>1.529197e+06</td>\n",
       "      <td>1.911497e+06</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>4</td>\n",
       "      <td>NaN</td>\n",
       "      <td>-0.694350</td>\n",
       "      <td>1.568248</td>\n",
       "      <td>0.479073</td>\n",
       "      <td>5.0</td>\n",
       "      <td>0.120653</td>\n",
       "      <td>22508</td>\n",
       "      <td>0.2654</td>\n",
       "      <td>13.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.000346</td>\n",
       "      <td>-0.000090</td>\n",
       "      <td>0.000288</td>\n",
       "      <td>-1.281102e-04</td>\n",
       "      <td>0.000074</td>\n",
       "      <td>0.000341</td>\n",
       "      <td>-0.005680</td>\n",
       "      <td>-0.002190</td>\n",
       "      <td>1.711569e+06</td>\n",
       "      <td>2.139462e+06</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>5</td>\n",
       "      <td>6.0</td>\n",
       "      <td>-1.736489</td>\n",
       "      <td>2.765531</td>\n",
       "      <td>1.245280</td>\n",
       "      <td>7.0</td>\n",
       "      <td>4.866985</td>\n",
       "      <td>22423</td>\n",
       "      <td>0.2138</td>\n",
       "      <td>13.0</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.001235</td>\n",
       "      <td>0.000027</td>\n",
       "      <td>0.002449</td>\n",
       "      <td>8.619882e-06</td>\n",
       "      <td>0.001209</td>\n",
       "      <td>-0.000004</td>\n",
       "      <td>0.036104</td>\n",
       "      <td>-0.026552</td>\n",
       "      <td>1.267270e+06</td>\n",
       "      <td>1.584088e+06</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 211 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   Id  Feature_1  Feature_2  Feature_3  Feature_4  Feature_5  Feature_6  \\\n",
       "0   1        NaN        NaN        NaN        NaN        8.0        NaN   \n",
       "1   2        NaN        NaN        NaN        NaN        3.0   0.388896   \n",
       "2   3        NaN  -0.696727   0.739591  -0.167928        9.0   0.471947   \n",
       "3   4        NaN  -0.694350   1.568248   0.479073        5.0   0.120653   \n",
       "4   5        6.0  -1.736489   2.765531   1.245280        7.0   4.866985   \n",
       "\n",
       "   Feature_7  Feature_8  Feature_9  ...   Ret_175   Ret_176   Ret_177  \\\n",
       "0      75751     0.2254       11.0  ... -0.002688  0.002246 -0.000838   \n",
       "1      17369     0.0166       13.0  ... -0.000129  0.000123  0.000248   \n",
       "2       8277     0.3650        9.0  ... -0.000524 -0.000394  0.000116   \n",
       "3      22508     0.2654       13.0  ...  0.000346 -0.000090  0.000288   \n",
       "4      22423     0.2138       13.0  ... -0.001235  0.000027  0.002449   \n",
       "\n",
       "        Ret_178   Ret_179   Ret_180  Ret_PlusOne  Ret_PlusTwo  \\\n",
       "0 -6.953224e-04  0.000003 -0.001974    -0.019512     0.028846   \n",
       "1  3.315418e-07  0.000003  0.000027    -0.002939    -0.010253   \n",
       "2  5.322557e-04  0.000274  0.000784    -0.024791     0.015711   \n",
       "3 -1.281102e-04  0.000074  0.000341    -0.005680    -0.002190   \n",
       "4  8.619882e-06  0.001209 -0.000004     0.036104    -0.026552   \n",
       "\n",
       "   Weight_Intraday  Weight_Daily  \n",
       "0     1.251508e+06  1.564385e+06  \n",
       "1     1.733950e+06  2.167438e+06  \n",
       "2     1.529197e+06  1.911497e+06  \n",
       "3     1.711569e+06  2.139462e+06  \n",
       "4     1.267270e+06  1.584088e+06  \n",
       "\n",
       "[5 rows x 211 columns]"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "training.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "dcab020c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Id</th>\n",
       "      <th>Feature_1</th>\n",
       "      <th>Feature_2</th>\n",
       "      <th>Feature_3</th>\n",
       "      <th>Feature_4</th>\n",
       "      <th>Feature_5</th>\n",
       "      <th>Feature_6</th>\n",
       "      <th>Feature_7</th>\n",
       "      <th>Feature_8</th>\n",
       "      <th>Feature_9</th>\n",
       "      <th>...</th>\n",
       "      <th>Ret_111</th>\n",
       "      <th>Ret_112</th>\n",
       "      <th>Ret_113</th>\n",
       "      <th>Ret_114</th>\n",
       "      <th>Ret_115</th>\n",
       "      <th>Ret_116</th>\n",
       "      <th>Ret_117</th>\n",
       "      <th>Ret_118</th>\n",
       "      <th>Ret_119</th>\n",
       "      <th>Ret_120</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.412783</td>\n",
       "      <td>-0.056284</td>\n",
       "      <td>NaN</td>\n",
       "      <td>10.0</td>\n",
       "      <td>0.413226</td>\n",
       "      <td>18871</td>\n",
       "      <td>0.2138</td>\n",
       "      <td>11.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.000370</td>\n",
       "      <td>-0.000762</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.000366</td>\n",
       "      <td>-0.002444</td>\n",
       "      <td>-0.001301</td>\n",
       "      <td>-0.000917</td>\n",
       "      <td>0.000762</td>\n",
       "      <td>-0.000556</td>\n",
       "      <td>0.000759</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.907973</td>\n",
       "      <td>1.002425</td>\n",
       "      <td>7.0</td>\n",
       "      <td>-0.257825</td>\n",
       "      <td>5852</td>\n",
       "      <td>0.2138</td>\n",
       "      <td>13.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.000457</td>\n",
       "      <td>0.000003</td>\n",
       "      <td>-0.000007</td>\n",
       "      <td>-0.000003</td>\n",
       "      <td>-0.000012</td>\n",
       "      <td>-0.000463</td>\n",
       "      <td>-0.000003</td>\n",
       "      <td>-0.000002</td>\n",
       "      <td>0.000468</td>\n",
       "      <td>-0.000012</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>3</td>\n",
       "      <td>NaN</td>\n",
       "      <td>-0.607583</td>\n",
       "      <td>1.076668</td>\n",
       "      <td>0.517865</td>\n",
       "      <td>5.0</td>\n",
       "      <td>0.947340</td>\n",
       "      <td>76935</td>\n",
       "      <td>0.0105</td>\n",
       "      <td>10.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.000003</td>\n",
       "      <td>0.000157</td>\n",
       "      <td>-0.000181</td>\n",
       "      <td>0.000003</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.000164</td>\n",
       "      <td>0.000353</td>\n",
       "      <td>0.000704</td>\n",
       "      <td>-0.000168</td>\n",
       "      <td>-0.000006</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>4</td>\n",
       "      <td>NaN</td>\n",
       "      <td>2.230240</td>\n",
       "      <td>0.223222</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>84573</td>\n",
       "      <td>0.3318</td>\n",
       "      <td>13.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.000010</td>\n",
       "      <td>-0.000792</td>\n",
       "      <td>-0.000479</td>\n",
       "      <td>0.000017</td>\n",
       "      <td>0.000170</td>\n",
       "      <td>-0.001079</td>\n",
       "      <td>0.000320</td>\n",
       "      <td>0.000006</td>\n",
       "      <td>0.001392</td>\n",
       "      <td>-0.001850</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>5</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.360399</td>\n",
       "      <td>0.597896</td>\n",
       "      <td>-0.145497</td>\n",
       "      <td>10.0</td>\n",
       "      <td>0.275744</td>\n",
       "      <td>89615</td>\n",
       "      <td>0.0099</td>\n",
       "      <td>8.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.000447</td>\n",
       "      <td>0.000489</td>\n",
       "      <td>-0.000233</td>\n",
       "      <td>-0.000495</td>\n",
       "      <td>0.000057</td>\n",
       "      <td>-0.000050</td>\n",
       "      <td>-0.000011</td>\n",
       "      <td>-0.000377</td>\n",
       "      <td>0.000227</td>\n",
       "      <td>-0.000114</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 147 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   Id  Feature_1  Feature_2  Feature_3  Feature_4  Feature_5  Feature_6  \\\n",
       "0   1        1.0   1.412783  -0.056284        NaN       10.0   0.413226   \n",
       "1   2        NaN        NaN   0.907973   1.002425        7.0  -0.257825   \n",
       "2   3        NaN  -0.607583   1.076668   0.517865        5.0   0.947340   \n",
       "3   4        NaN   2.230240   0.223222        NaN        1.0        NaN   \n",
       "4   5        NaN   0.360399   0.597896  -0.145497       10.0   0.275744   \n",
       "\n",
       "   Feature_7  Feature_8  Feature_9  ...   Ret_111   Ret_112   Ret_113  \\\n",
       "0      18871     0.2138       11.0  ...  0.000370 -0.000762       NaN   \n",
       "1       5852     0.2138       13.0  ...  0.000457  0.000003 -0.000007   \n",
       "2      76935     0.0105       10.0  ...  0.000003  0.000157 -0.000181   \n",
       "3      84573     0.3318       13.0  ...  0.000010 -0.000792 -0.000479   \n",
       "4      89615     0.0099        8.0  ...  0.000447  0.000489 -0.000233   \n",
       "\n",
       "    Ret_114   Ret_115   Ret_116   Ret_117   Ret_118   Ret_119   Ret_120  \n",
       "0  0.000366 -0.002444 -0.001301 -0.000917  0.000762 -0.000556  0.000759  \n",
       "1 -0.000003 -0.000012 -0.000463 -0.000003 -0.000002  0.000468 -0.000012  \n",
       "2  0.000003       NaN  0.000164  0.000353  0.000704 -0.000168 -0.000006  \n",
       "3  0.000017  0.000170 -0.001079  0.000320  0.000006  0.001392 -0.001850  \n",
       "4 -0.000495  0.000057 -0.000050 -0.000011 -0.000377  0.000227 -0.000114  \n",
       "\n",
       "[5 rows x 147 columns]"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test = pd.read_csv(\"test_2.csv\")\n",
    "test.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "1dd43c1d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Feature_1       0.167175\n",
       "Feature_10      0.513225\n",
       "Feature_2       0.771350\n",
       "Feature_20      0.804350\n",
       "Feature_4       0.806975\n",
       "                  ...   \n",
       "Ret_135         1.000000\n",
       "Ret_134         1.000000\n",
       "Ret_133         1.000000\n",
       "Ret_139         1.000000\n",
       "Weight_Daily    1.000000\n",
       "Length: 211, dtype: float64"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "notNanPercentage = np.sum(~training.isna())/len(training)\n",
    "notNanPercentage.sort_values()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3bf45152",
   "metadata": {},
   "source": [
    "We could see only 16% data of Feature_1 column and <50% data of of Feature_10 column contain values, so we decide to drop those two columns when we build the model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "b6672e57",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 1296x288 with 4 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.figure(figsize=(18,4))\n",
    "plt.subplot(1,4,1)\n",
    "plt.hist(training.Ret_MinusTwo, bins=100)\n",
    "plt.subplot(1,4,2)\n",
    "plt.hist(training.Ret_MinusOne, bins=100)\n",
    "plt.subplot(1,4,3)\n",
    "plt.hist(training.Ret_PlusOne, bins=100) # target variable\n",
    "plt.subplot(1,4,4)\n",
    "plt.hist(training.Ret_PlusTwo, bins=100) # target variable\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dde37a1f",
   "metadata": {},
   "source": [
    "Since we found both features (Ret_MinusTwo, Ret_MinusOne) and target variables are approximately normal, we could assume they are multi-normal, and the linear regression assumption-multinormal distribution-is satisfied."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "8e5e87de",
   "metadata": {},
   "outputs": [],
   "source": [
    "train = training.sample(frac=0.9,random_state=42)\n",
    "validation = training.drop(train.index)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "71cf8556",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "36000"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "da707045",
   "metadata": {},
   "outputs": [],
   "source": [
    "feature = [ 'Ret_MinusTwo','Ret_MinusOne']\n",
    "\n",
    "feature += ['Feature_{}'.format(i) for i in range(1, 26)]\n",
    "feature.remove('Feature_1')\n",
    "feature.remove('Feature_10')\n",
    "\n",
    "#feature += ['Ret_{}'.format(i) for i in range(2, 121)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "7b5fd833",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Prepare features for modeling daily returns\n",
    "Ret_PlusOneFeature = feature + ['Ret_PlusOne']\n",
    "Ret_PlusTwoFeature = feature + ['Ret_PlusTwo'] "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "fd47edd3",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Ret_MinusTwo</th>\n",
       "      <th>Ret_MinusOne</th>\n",
       "      <th>Feature_2</th>\n",
       "      <th>Feature_3</th>\n",
       "      <th>Feature_4</th>\n",
       "      <th>Feature_5</th>\n",
       "      <th>Feature_6</th>\n",
       "      <th>Feature_7</th>\n",
       "      <th>Feature_8</th>\n",
       "      <th>Feature_9</th>\n",
       "      <th>...</th>\n",
       "      <th>Feature_17</th>\n",
       "      <th>Feature_18</th>\n",
       "      <th>Feature_19</th>\n",
       "      <th>Feature_20</th>\n",
       "      <th>Feature_21</th>\n",
       "      <th>Feature_22</th>\n",
       "      <th>Feature_23</th>\n",
       "      <th>Feature_24</th>\n",
       "      <th>Feature_25</th>\n",
       "      <th>Ret_PlusOne</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>32823</th>\n",
       "      <td>-0.013260</td>\n",
       "      <td>0.000590</td>\n",
       "      <td>0.479581</td>\n",
       "      <td>0.199240</td>\n",
       "      <td>-0.788162</td>\n",
       "      <td>5.0</td>\n",
       "      <td>-0.758338</td>\n",
       "      <td>86137</td>\n",
       "      <td>0.3650</td>\n",
       "      <td>9.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.128854</td>\n",
       "      <td>-0.319879</td>\n",
       "      <td>-0.961432</td>\n",
       "      <td>3.0</td>\n",
       "      <td>-0.728740</td>\n",
       "      <td>-0.381317</td>\n",
       "      <td>0.304771</td>\n",
       "      <td>-0.328039</td>\n",
       "      <td>-0.305417</td>\n",
       "      <td>0.011966</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16298</th>\n",
       "      <td>0.015272</td>\n",
       "      <td>-0.087335</td>\n",
       "      <td>0.261451</td>\n",
       "      <td>-0.128693</td>\n",
       "      <td>-0.048090</td>\n",
       "      <td>7.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>51411</td>\n",
       "      <td>0.2654</td>\n",
       "      <td>11.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.158995</td>\n",
       "      <td>-0.444783</td>\n",
       "      <td>-0.393301</td>\n",
       "      <td>2.0</td>\n",
       "      <td>-0.660029</td>\n",
       "      <td>-0.118927</td>\n",
       "      <td>-0.164613</td>\n",
       "      <td>-0.032897</td>\n",
       "      <td>-0.175894</td>\n",
       "      <td>-0.004402</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>28505</th>\n",
       "      <td>-0.004651</td>\n",
       "      <td>-0.007407</td>\n",
       "      <td>0.132693</td>\n",
       "      <td>0.011800</td>\n",
       "      <td>0.025669</td>\n",
       "      <td>8.0</td>\n",
       "      <td>-0.145155</td>\n",
       "      <td>92235</td>\n",
       "      <td>0.2109</td>\n",
       "      <td>14.0</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.774073</td>\n",
       "      <td>0.699686</td>\n",
       "      <td>-1.286713</td>\n",
       "      <td>7.0</td>\n",
       "      <td>-0.286466</td>\n",
       "      <td>-0.206454</td>\n",
       "      <td>0.957931</td>\n",
       "      <td>-2.327268</td>\n",
       "      <td>-0.679526</td>\n",
       "      <td>-0.001938</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6689</th>\n",
       "      <td>-0.043868</td>\n",
       "      <td>-0.015366</td>\n",
       "      <td>0.707221</td>\n",
       "      <td>-0.799214</td>\n",
       "      <td>-0.878790</td>\n",
       "      <td>5.0</td>\n",
       "      <td>-0.513552</td>\n",
       "      <td>8912</td>\n",
       "      <td>0.0102</td>\n",
       "      <td>5.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.776121</td>\n",
       "      <td>-0.602150</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>-1.290809</td>\n",
       "      <td>0.113874</td>\n",
       "      <td>-0.151860</td>\n",
       "      <td>0.686725</td>\n",
       "      <td>-0.052387</td>\n",
       "      <td>0.017789</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>26893</th>\n",
       "      <td>-0.007558</td>\n",
       "      <td>-0.017871</td>\n",
       "      <td>1.471640</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>2.0</td>\n",
       "      <td>0.345870</td>\n",
       "      <td>58934</td>\n",
       "      <td>0.0111</td>\n",
       "      <td>6.0</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.347625</td>\n",
       "      <td>0.143506</td>\n",
       "      <td>-0.866299</td>\n",
       "      <td>2.0</td>\n",
       "      <td>0.137590</td>\n",
       "      <td>-2.136254</td>\n",
       "      <td>0.791216</td>\n",
       "      <td>1.145140</td>\n",
       "      <td>-0.596923</td>\n",
       "      <td>0.007983</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 26 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "       Ret_MinusTwo  Ret_MinusOne  Feature_2  Feature_3  Feature_4  Feature_5  \\\n",
       "32823     -0.013260      0.000590   0.479581   0.199240  -0.788162        5.0   \n",
       "16298      0.015272     -0.087335   0.261451  -0.128693  -0.048090        7.0   \n",
       "28505     -0.004651     -0.007407   0.132693   0.011800   0.025669        8.0   \n",
       "6689      -0.043868     -0.015366   0.707221  -0.799214  -0.878790        5.0   \n",
       "26893     -0.007558     -0.017871   1.471640        NaN        NaN        2.0   \n",
       "\n",
       "       Feature_6  Feature_7  Feature_8  Feature_9  ...  Feature_17  \\\n",
       "32823  -0.758338      86137     0.3650        9.0  ...    0.128854   \n",
       "16298        NaN      51411     0.2654       11.0  ...    0.158995   \n",
       "28505  -0.145155      92235     0.2109       14.0  ...   -0.774073   \n",
       "6689   -0.513552       8912     0.0102        5.0  ...    0.776121   \n",
       "26893   0.345870      58934     0.0111        6.0  ...   -0.347625   \n",
       "\n",
       "       Feature_18  Feature_19  Feature_20  Feature_21  Feature_22  Feature_23  \\\n",
       "32823   -0.319879   -0.961432         3.0   -0.728740   -0.381317    0.304771   \n",
       "16298   -0.444783   -0.393301         2.0   -0.660029   -0.118927   -0.164613   \n",
       "28505    0.699686   -1.286713         7.0   -0.286466   -0.206454    0.957931   \n",
       "6689    -0.602150         NaN         NaN   -1.290809    0.113874   -0.151860   \n",
       "26893    0.143506   -0.866299         2.0    0.137590   -2.136254    0.791216   \n",
       "\n",
       "       Feature_24  Feature_25  Ret_PlusOne  \n",
       "32823   -0.328039   -0.305417     0.011966  \n",
       "16298   -0.032897   -0.175894    -0.004402  \n",
       "28505   -2.327268   -0.679526    -0.001938  \n",
       "6689     0.686725   -0.052387     0.017789  \n",
       "26893    1.145140   -0.596923     0.007983  \n",
       "\n",
       "[5 rows x 26 columns]"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train[Ret_PlusOneFeature].head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d3777a37",
   "metadata": {},
   "source": [
    "### AutoML predictor for modeling D+1, D+2 daily returns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "9260d6e2",
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "No path specified. Models will be saved in: \"AutogluonModels/ag-20220716_195336/\"\n",
      "Presets specified: ['best_quality']\n",
      "Beginning AutoGluon training ... Time limit = 600s\n",
      "AutoGluon will save models to \"AutogluonModels/ag-20220716_195336/\"\n",
      "AutoGluon Version:  0.5.0\n",
      "Python Version:     3.8.12\n",
      "Operating System:   Linux\n",
      "Train Data Rows:    36000\n",
      "Train Data Columns: 25\n",
      "Label Column: Ret_PlusOne\n",
      "Preprocessing data ...\n",
      "AutoGluon infers your prediction problem is: 'regression' (because dtype of label-column == float and many unique label-values observed).\n",
      "\tLabel info (max, min, mean, stddev): (0.7956016001987842, -0.6276902119251764, -0.00017, 0.02518)\n",
      "\tIf 'regression' is not the correct problem_type, please manually specify the problem_type parameter during predictor init (You may specify problem_type as one of: ['binary', 'multiclass', 'regression'])\n",
      "Using Feature Generators to preprocess the data ...\n",
      "Fitting AutoMLPipelineFeatureGenerator...\n",
      "\tAvailable Memory:                    14934.47 MB\n",
      "\tTrain Data (Original)  Memory Usage: 7.2 MB (0.0% of available memory)\n",
      "\tInferring data type of each feature based on column values. Set feature_metadata_in to manually specify special dtypes of the features.\n",
      "\tStage 1 Generators:\n",
      "\t\tFitting AsTypeFeatureGenerator...\n",
      "\tStage 2 Generators:\n",
      "\t\tFitting FillNaFeatureGenerator...\n",
      "\tStage 3 Generators:\n",
      "\t\tFitting IdentityFeatureGenerator...\n",
      "\tStage 4 Generators:\n",
      "\t\tFitting DropUniqueFeatureGenerator...\n",
      "\tTypes of features in original data (raw dtype, special dtypes):\n",
      "\t\t('float', []) : 24 | ['Ret_MinusTwo', 'Ret_MinusOne', 'Feature_2', 'Feature_3', 'Feature_4', ...]\n",
      "\t\t('int', [])   :  1 | ['Feature_7']\n",
      "\tTypes of features in processed data (raw dtype, special dtypes):\n",
      "\t\t('float', []) : 24 | ['Ret_MinusTwo', 'Ret_MinusOne', 'Feature_2', 'Feature_3', 'Feature_4', ...]\n",
      "\t\t('int', [])   :  1 | ['Feature_7']\n",
      "\t0.2s = Fit runtime\n",
      "\t25 features in original data used to generate 25 features in processed data.\n",
      "\tTrain Data (Processed) Memory Usage: 7.2 MB (0.0% of available memory)\n",
      "Data preprocessing and feature engineering runtime = 0.22s ...\n",
      "AutoGluon will gauge predictive performance using evaluation metric: 'root_mean_squared_error'\n",
      "\tThis metric's sign has been flipped to adhere to being higher_is_better. The metric score can be multiplied by -1 to get the metric value.\n",
      "\tTo change this, specify the eval_metric parameter of Predictor()\n",
      "AutoGluon will fit 2 stack levels (L1 to L2) ...\n",
      "Fitting 11 L1 models ...\n",
      "Fitting model: KNeighborsUnif_BAG_L1 ... Training model for up to 399.75s of the 599.78s of remaining time.\n",
      "\t-0.0217\t = Validation score   (-root_mean_squared_error)\n",
      "\t0.04s\t = Training   runtime\n",
      "\t33.16s\t = Validation runtime\n",
      "Fitting model: KNeighborsDist_BAG_L1 ... Training model for up to 365.66s of the 565.68s of remaining time.\n",
      "\t-0.0216\t = Validation score   (-root_mean_squared_error)\n",
      "\t0.04s\t = Training   runtime\n",
      "\t32.16s\t = Validation runtime\n",
      "Fitting model: LightGBMXT_BAG_L1 ... Training model for up to 332.85s of the 532.87s of remaining time.\n",
      "\tFitting 8 child models (S1F1 - S1F8) | Fitting with ParallelLocalFoldFittingStrategy\n",
      "\t-0.0249\t = Validation score   (-root_mean_squared_error)\n",
      "\t14.34s\t = Training   runtime\n",
      "\t0.52s\t = Validation runtime\n",
      "Fitting model: LightGBM_BAG_L1 ... Training model for up to 309.52s of the 509.55s of remaining time.\n",
      "\tFitting 8 child models (S1F1 - S1F8) | Fitting with ParallelLocalFoldFittingStrategy\n",
      "\t-0.0239\t = Validation score   (-root_mean_squared_error)\n",
      "\t17.9s\t = Training   runtime\n",
      "\t1.03s\t = Validation runtime\n",
      "Fitting model: RandomForestMSE_BAG_L1 ... Training model for up to 288.51s of the 488.54s of remaining time.\n",
      "\t-0.0229\t = Validation score   (-root_mean_squared_error)\n",
      "\t137.33s\t = Training   runtime\n",
      "\t2.22s\t = Validation runtime\n",
      "Fitting model: CatBoost_BAG_L1 ... Training model for up to 148.11s of the 348.13s of remaining time.\n",
      "\tFitting 8 child models (S1F1 - S1F8) | Fitting with ParallelLocalFoldFittingStrategy\n",
      "\t-0.024\t = Validation score   (-root_mean_squared_error)\n",
      "\t107.22s\t = Training   runtime\n",
      "\t0.16s\t = Validation runtime\n",
      "Fitting model: ExtraTreesMSE_BAG_L1 ... Training model for up to 38.49s of the 238.51s of remaining time.\n",
      "\t-0.0244\t = Validation score   (-root_mean_squared_error)\n",
      "\t19.11s\t = Training   runtime\n",
      "\t2.05s\t = Validation runtime\n",
      "Fitting model: NeuralNetFastAI_BAG_L1 ... Training model for up to 16.45s of the 216.47s of remaining time.\n",
      "\tFitting 8 child models (S1F1 - S1F8) | Fitting with ParallelLocalFoldFittingStrategy\n",
      "\t-0.0253\t = Validation score   (-root_mean_squared_error)\n",
      "\t129.05s\t = Training   runtime\n",
      "\t0.73s\t = Validation runtime\n",
      "Completed 1/20 k-fold bagging repeats ...\n",
      "Fitting model: WeightedEnsemble_L2 ... Training model for up to 360.0s of the 84.86s of remaining time.\n",
      "\t-0.0211\t = Validation score   (-root_mean_squared_error)\n",
      "\t0.62s\t = Training   runtime\n",
      "\t0.0s\t = Validation runtime\n",
      "Fitting 9 L2 models ...\n",
      "Fitting model: LightGBMXT_BAG_L2 ... Training model for up to 84.22s of the 84.21s of remaining time.\n",
      "\tFitting 8 child models (S1F1 - S1F8) | Fitting with ParallelLocalFoldFittingStrategy\n",
      "\t-0.0211\t = Validation score   (-root_mean_squared_error)\n",
      "\t12.62s\t = Training   runtime\n",
      "\t0.38s\t = Validation runtime\n",
      "Fitting model: LightGBM_BAG_L2 ... Training model for up to 68.7s of the 68.68s of remaining time.\n",
      "\tFitting 8 child models (S1F1 - S1F8) | Fitting with ParallelLocalFoldFittingStrategy\n",
      "\t-0.021\t = Validation score   (-root_mean_squared_error)\n",
      "\t11.65s\t = Training   runtime\n",
      "\t0.3s\t = Validation runtime\n",
      "Fitting model: RandomForestMSE_BAG_L2 ... Training model for up to 54.31s of the 54.29s of remaining time.\n",
      "\t-0.0212\t = Validation score   (-root_mean_squared_error)\n",
      "\t170.46s\t = Training   runtime\n",
      "\t2.4s\t = Validation runtime\n",
      "Completed 1/20 k-fold bagging repeats ...\n",
      "Fitting model: WeightedEnsemble_L3 ... Training model for up to 360.0s of the -119.51s of remaining time.\n",
      "\t-0.0209\t = Validation score   (-root_mean_squared_error)\n",
      "\t0.31s\t = Training   runtime\n",
      "\t0.0s\t = Validation runtime\n",
      "AutoGluon training complete, total runtime = 719.84s ... Best model: \"WeightedEnsemble_L3\"\n",
      "TabularPredictor saved. To load, use: predictor = TabularPredictor.load(\"AutogluonModels/ag-20220716_195336/\")\n"
     ]
    }
   ],
   "source": [
    "predictor_D1 = TabularPredictor(label=\"Ret_PlusOne\",\n",
    "                                eval_metric=\"root_mean_squared_error\"\n",
    "                               ).fit(\n",
    "    train_data=train[Ret_PlusOneFeature], \n",
    "    time_limit=600, \n",
    "    presets=\"best_quality\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "f50dc0c3",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.018975024779882443"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.metrics import mean_squared_error\n",
    "predictionD1 = predictor_D1.predict(validation[feature])\n",
    "D1Error = np.sqrt(mean_squared_error(validation[\"Ret_PlusOne\"], predictionD1))\n",
    "D1Error"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "10790f78",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "No path specified. Models will be saved in: \"AutogluonModels/ag-20220716_200623/\"\n",
      "AutoGluon infers your prediction problem is: 'regression' (because dtype of label-column == float and many unique label-values observed).\n",
      "\tIf 'regression' is not the correct problem_type, please manually specify the problem_type parameter during predictor init (You may specify problem_type as one of: ['binary', 'multiclass', 'regression'])\n",
      "AutoGluon will gauge predictive performance using evaluation metric: 'root_mean_squared_error'\n",
      "\tThis metric's sign has been flipped to adhere to being higher_is_better. The metric score can be multiplied by -1 to get the metric value.\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "0.019068396339328015"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "predictor_D2 = TabularPredictor(label=\"Ret_PlusTwo\",\n",
    "                                eval_metric=\"root_mean_squared_error\",\n",
    "                                verbosity = 1).fit(\n",
    "    train_data=train[Ret_PlusTwoFeature], \n",
    "    time_limit=600, \n",
    "    presets=\"best_quality\")\n",
    "predictionD2 = predictor_D2.predict(validation[feature])\n",
    "D2Error = np.sqrt(mean_squared_error(validation[\"Ret_PlusTwo\"], predictionD2))\n",
    "D2Error"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "80bf6074",
   "metadata": {},
   "source": [
    "The AutoGluon algorithm automatically chooses the best machine learning model for our predictor, and the validation error (RMSE) of AutoML predictor on D+1 return is 0.0189 and 0.01907 for D+2 return. In total, the RMSE error for D+1 & D+2 return is 0.03797."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4f29f971",
   "metadata": {},
   "source": [
    "### Deep Learning predictor for modeling D+1, D+2 daily returns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "193dc8d8",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "b3fc05fb",
   "metadata": {},
   "outputs": [],
   "source": [
    "x_col = feature\n",
    "y_col = ['Ret_PlusOne','Ret_PlusTwo']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "3f6c6e8e",
   "metadata": {},
   "outputs": [],
   "source": [
    "train = train.fillna(method=\"bfill\").fillna(method=\"ffill\")\n",
    "validation = validation.fillna(method=\"bfill\").fillna(method=\"ffill\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "48b0ac69",
   "metadata": {},
   "outputs": [],
   "source": [
    "x_train, y_train = train[x_col].values, train[y_col].values\n",
    "x_test, y_test = validation[x_col].values, validation[y_col].values\n",
    "\n",
    "import torch.utils.data as data_utils\n",
    "PyTorchtrain = data_utils.TensorDataset(torch.Tensor(x_train), torch.Tensor(y_train))\n",
    "train_loader = data_utils.DataLoader(PyTorchtrain, batch_size=128, shuffle=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "2e571b10",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([16, 25])\n",
      "torch.Size([16])\n",
      "torch.Size([4, 16])\n",
      "torch.Size([4])\n",
      "torch.Size([2, 4])\n",
      "torch.Size([2])\n"
     ]
    }
   ],
   "source": [
    "Dmodel = nn.Sequential(nn.Linear(25, 16),\n",
    "                      nn.Tanh(),\n",
    "                      nn.Linear(16, 4),\n",
    "                      nn.Tanh(),\n",
    "                      nn.Linear(4, 2))\n",
    "criterion = torch.nn.MSELoss(reduction='sum')\n",
    "optimiser = torch.optim.SGD(Dmodel.parameters(), lr =1e-5)\n",
    "for i in range(len(list(Dmodel.parameters()))):\n",
    "    print(list(Dmodel.parameters())[i].size())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6656a41d",
   "metadata": {},
   "source": [
    "Since the magnitude of our target variable is very small (usually returns are smaller than 0.1), I have set tanh() as the activation function, which returns values from -1 to 1. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "1d831acb",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch  0 RMSE:  0.08016396\n",
      "Epoch  1 RMSE:  0.034941074\n",
      "Epoch  2 RMSE:  0.034937304\n",
      "Epoch  3 RMSE:  0.034937315\n",
      "Epoch  4 RMSE:  0.034937315\n",
      "Epoch  5 RMSE:  0.034937315\n",
      "Epoch  6 RMSE:  0.034937315\n",
      "Epoch  7 RMSE:  0.03493732\n",
      "Epoch  8 RMSE:  0.034937315\n",
      "Epoch  9 RMSE:  0.034937315\n"
     ]
    }
   ],
   "source": [
    "num_epochs = 10\n",
    "tot = len(train)\n",
    "for t in range(num_epochs):\n",
    "    running_loss = 0\n",
    "    for data, target in train_loader:\n",
    "        pred = Dmodel(data)\n",
    "        loss = criterion(pred, target)\n",
    "        running_loss += loss\n",
    "        #print(pred, target)\n",
    "        optimiser.zero_grad()\n",
    "        loss.backward()\n",
    "        optimiser.step()\n",
    "    print(\"Epoch \", t, \"RMSE: \", np.sqrt((running_loss/tot).detach().numpy()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "b117ecae",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.033492102204435104"
      ]
     },
     "execution_count": 42,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "D1D2pred = Dmodel(torch.Tensor(x_test))\n",
    "DError_torch = criterion(D1D2pred, torch.Tensor(y_test))\n",
    "DError = np.sqrt(DError_torch.detach().numpy()/len(validation))\n",
    "DError"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c4a5b77b",
   "metadata": {},
   "source": [
    "After comparing the validation error (RMSE for D+1 & D+2) for each predictior, the deep learning predictor (even with very simple model structure) has a lower RMSE; therefore, we will choose deep learning model for our daily return predictor."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f4a423ae",
   "metadata": {},
   "source": [
    "### Deep Learning predictor for modeling Intraday returns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "id": "2860ffd5",
   "metadata": {},
   "outputs": [],
   "source": [
    "Intrafeature = feature + ['Ret_{}'.format(i) for i in range(2, 121)]\n",
    "x_col = Intrafeature\n",
    "y_col = ['Ret_{}'.format(i) for i in range(121, 181)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "id": "366f0c78",
   "metadata": {},
   "outputs": [],
   "source": [
    "x_train, y_train = train[x_col].values, train[y_col].values\n",
    "x_test, y_test = validation[x_col].values, validation[y_col].values\n",
    "\n",
    "import torch.utils.data as data_utils\n",
    "PyTorchtrain = data_utils.TensorDataset(torch.Tensor(x_train), torch.Tensor(y_train))\n",
    "train_loader = data_utils.DataLoader(PyTorchtrain, batch_size=16, shuffle=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "id": "2fc721bd",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([256, 144])\n",
      "torch.Size([256])\n",
      "torch.Size([128, 256])\n",
      "torch.Size([128])\n",
      "torch.Size([64, 128])\n",
      "torch.Size([64])\n",
      "torch.Size([60, 64])\n",
      "torch.Size([60])\n"
     ]
    }
   ],
   "source": [
    "IntraModel = nn.Sequential(nn.Linear(144, 256),\n",
    "                           nn.Tanh(),\n",
    "                           nn.Linear(256, 128),\n",
    "                           nn.Tanh(),\n",
    "                           nn.Linear(128, 64),\n",
    "                           nn.Tanh(),\n",
    "                           nn.Linear(64, 60))\n",
    "criterion = torch.nn.MSELoss(reduction='sum')\n",
    "optimiser = torch.optim.SGD(IntraModel.parameters(), lr =1e-5)\n",
    "for i in range(len(list(IntraModel.parameters()))):\n",
    "    print(list(IntraModel.parameters())[i].size())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "id": "dfae7eb0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch  0 RMSE:  0.19037332\n",
      "Epoch  1 RMSE:  0.011932794\n",
      "Epoch  2 RMSE:  0.009378587\n",
      "Epoch  3 RMSE:  0.009283561\n",
      "Epoch  4 RMSE:  0.009240259\n",
      "Epoch  5 RMSE:  0.00921192\n",
      "Epoch  6 RMSE:  0.009191716\n",
      "Epoch  7 RMSE:  0.009176469\n",
      "Epoch  8 RMSE:  0.009164477\n",
      "Epoch  9 RMSE:  0.009154745\n",
      "Epoch  10 RMSE:  0.009146656\n",
      "Epoch  11 RMSE:  0.009139792\n",
      "Epoch  12 RMSE:  0.009133893\n",
      "Epoch  13 RMSE:  0.009128748\n",
      "Epoch  14 RMSE:  0.009124211\n",
      "Epoch  15 RMSE:  0.009120183\n",
      "Epoch  16 RMSE:  0.009116575\n",
      "Epoch  17 RMSE:  0.009113327\n",
      "Epoch  18 RMSE:  0.009110377\n",
      "Epoch  19 RMSE:  0.009107693\n"
     ]
    }
   ],
   "source": [
    "num_epochs = 20\n",
    "tot = len(train)\n",
    "for t in range(num_epochs):\n",
    "    running_loss = 0\n",
    "    for data, target in train_loader:\n",
    "        pred = IntraModel(data)\n",
    "        loss = criterion(pred, target)\n",
    "        running_loss += loss\n",
    "        #print(pred, target)\n",
    "        optimiser.zero_grad()\n",
    "        loss.backward()\n",
    "        optimiser.step()\n",
    "    print(\"Epoch \", t, \"RMSE: \", np.sqrt((running_loss/tot).detach().numpy()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "id": "75e37b6a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.008903848675699601"
      ]
     },
     "execution_count": 61,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Intrapred = IntraModel(torch.Tensor(x_test))\n",
    "IntraError_torch = criterion(Intrapred, torch.Tensor(y_test))\n",
    "IntraError = np.sqrt(IntraError_torch.detach().numpy()/len(validation))\n",
    "IntraError"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1975b918",
   "metadata": {},
   "source": [
    "## Inference"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "id": "907ed76d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Id</th>\n",
       "      <th>Predicted</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1_1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1_2</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1_3</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "    Id  Predicted\n",
       "0  1_1          0\n",
       "1  1_2          0\n",
       "2  1_3          0"
      ]
     },
     "execution_count": 76,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "submission = pd.read_csv(\"sample_submission_2.csv\")\n",
    "submission.head(3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "id": "a34acadf",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(7440000, 2)\n"
     ]
    }
   ],
   "source": [
    "print(submission.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "id": "1fb77206",
   "metadata": {},
   "outputs": [],
   "source": [
    "test = test.fillna(method=\"bfill\").fillna(method=\"ffill\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "id": "5ea9e1ff",
   "metadata": {},
   "outputs": [],
   "source": [
    "D1D2TestPred_torch = Dmodel(torch.Tensor(test[feature].values))\n",
    "D1D2TestPred = D1D2TestPred_torch.detach().numpy()\n",
    "IntraTestPred_torch = IntraModel(torch.Tensor(test[Intrafeature].values))\n",
    "IntraTestPred = IntraTestPred_torch.detach().numpy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "id": "28c229c5",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([-2.2962689e-05, -4.2147934e-05,  2.4154782e-05,  2.4098903e-05,\n",
       "        3.7476420e-06,  1.5273690e-06,  4.9471855e-06,  1.8365681e-05,\n",
       "        4.9248338e-06,  9.9828467e-06, -1.0117888e-05, -3.5494566e-05,\n",
       "        7.6182187e-06, -1.5627593e-05,  8.0995262e-05, -2.8013252e-05,\n",
       "        5.6083780e-05,  3.0376017e-05, -4.4248998e-05,  1.2241304e-05,\n",
       "       -1.8127263e-05, -3.6180019e-05, -2.3446977e-05, -3.7096441e-05,\n",
       "       -1.4975667e-06, -1.0341406e-05, -9.7453594e-06,  3.6355108e-05,\n",
       "       -2.0060688e-05, -7.7188015e-06, -1.0743737e-05, -2.4661422e-06,\n",
       "       -5.2360818e-05, -4.1127205e-06, -1.2665987e-05,  2.7552247e-05,\n",
       "       -2.3345463e-05,  1.1894852e-05,  1.0408461e-05,  5.5722892e-05,\n",
       "       -4.6957284e-06, -3.0770898e-06, -4.9896538e-05, -2.0895153e-05,\n",
       "        2.5443733e-05, -6.1117287e-05,  7.4077398e-05, -3.2503158e-07,\n",
       "        3.9115548e-06,  4.6502799e-05, -7.3239207e-06, -4.1581690e-05,\n",
       "        3.2968819e-05, -8.2626939e-06,  7.7016652e-05, -1.8492341e-05,\n",
       "       -1.4364719e-05, -4.0769577e-05, -2.5719404e-05, -8.0049038e-05],\n",
       "      dtype=float32)"
      ]
     },
     "execution_count": 80,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "IntraTestPred[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "id": "1644c082",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([-0.00026682,  0.00017121], dtype=float32)"
      ]
     },
     "execution_count": 79,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "D1D2TestPred[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "id": "a7d2d11d",
   "metadata": {},
   "outputs": [],
   "source": [
    "res = []\n",
    "for i in range(120000):\n",
    "    res += list(IntraTestPred[i])\n",
    "    res += list(D1D2TestPred[i])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "id": "cda34973",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Id</th>\n",
       "      <th>Predicted</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1_1</td>\n",
       "      <td>-0.000023</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1_2</td>\n",
       "      <td>-0.000042</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1_3</td>\n",
       "      <td>0.000024</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1_4</td>\n",
       "      <td>0.000024</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1_5</td>\n",
       "      <td>0.000004</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "    Id  Predicted\n",
       "0  1_1  -0.000023\n",
       "1  1_2  -0.000042\n",
       "2  1_3   0.000024\n",
       "3  1_4   0.000024\n",
       "4  1_5   0.000004"
      ]
     },
     "execution_count": 83,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "submission[\"Predicted\"] = res\n",
    "submission.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "id": "ca598d4a",
   "metadata": {},
   "outputs": [],
   "source": [
    "submission.to_csv(\"submission.csv\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "conda_pytorch_p38",
   "language": "python",
   "name": "conda_pytorch_p38"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
